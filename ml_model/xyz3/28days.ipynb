{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "478f1b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: INSTALL AND IMPORT REQUIRED LIBRARIES\n",
    "# ============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Time Series Analysis\n",
    "try:\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "except ImportError:\n",
    "    print(\"Installing statsmodels...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"statsmodels\"])\n",
    "    from statsmodels.tsa.arima.model import ARIMA\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError:\n",
    "    print(\"Installing xgboost...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
    "    import xgboost as xgb\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147c979e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Loading commodity price data from your file...\n",
      "‚úÖ Data loaded successfully: 11990 records\n",
      "\n",
      "üìã Data Structure:\n",
      "   Sl no.              District Name                Market Name Commodity  \\\n",
      "0       1  Chattrapati Sambhajinagar  Chattrapati Sambhajinagar     Apple   \n",
      "1       2  Chattrapati Sambhajinagar  Chattrapati Sambhajinagar     Apple   \n",
      "2       3  Chattrapati Sambhajinagar  Chattrapati Sambhajinagar     Apple   \n",
      "3       4  Chattrapati Sambhajinagar  Chattrapati Sambhajinagar     Apple   \n",
      "4       5  Chattrapati Sambhajinagar  Chattrapati Sambhajinagar     Apple   \n",
      "\n",
      "  Variety  Grade  Min Price (Rs./Quintal)  Max Price (Rs./Quintal) Price Date  \\\n",
      "0   Other  Local                     1000                    15000  12-Jan-25   \n",
      "1   Other  Local                     3400                     9700  24-Oct-24   \n",
      "2   Other  Local                     3500                     8500  23-Sep-24   \n",
      "3   Other  Local                     3500                     9500   9-Dec-24   \n",
      "4   Other  Local                     4000                    11000  11-Dec-24   \n",
      "\n",
      "   Modal Price (Rs./kg)  Min Price   Max price  \n",
      "0                 125.0        10.0      150.0  \n",
      "1                  65.5        34.0       97.0  \n",
      "2                  60.0        35.0       85.0  \n",
      "3                  65.0        35.0       95.0  \n",
      "4                  75.0        40.0      110.0  \n",
      "\n",
      "Columns: ['Sl no.', 'District Name', 'Market Name', 'Commodity', 'Variety', 'Grade', 'Min Price (Rs./Quintal)', 'Max Price (Rs./Quintal)', 'Price Date', 'Modal Price (Rs./kg)', 'Min Price ', 'Max price']\n",
      "‚úÖ Data preprocessed: 10402 records after cleaning\n",
      "üìà Date range: 2024-07-27 00:00:00 to 2025-07-27 00:00:00\n",
      "üè∑Ô∏è  Commodities: 10 unique commodities\n",
      "üè¢ Districts: 5 unique districts\n",
      "üìä Commodities list: Tomato, Brinjal, Onion, Cabbage, Potato, Banana, Papaya, Guava, Grapes, Apple\n",
      "\n",
      "üéâ Data loading completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: LOAD AND PREPROCESS YOUR DATA\n",
    "# ============================================================================\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"Load and preprocess your commodity price data\"\"\"\n",
    "    print(\"üìä Loading commodity price data from your file...\")\n",
    "    \n",
    "    try:\n",
    "        # Load data\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"‚úÖ Data loaded successfully: {len(df)} records\")\n",
    "        \n",
    "        # Display first few rows to understand structure\n",
    "        print(\"\\nüìã Data Structure:\")\n",
    "        print(df.head())\n",
    "        print(f\"\\nColumns: {list(df.columns)}\")\n",
    "        \n",
    "        # Clean column names (remove extra spaces)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        # Convert Price Date to datetime\n",
    "        df['Date'] = pd.to_datetime(df['Price Date'], format='%d-%b-%y', errors='coerce')\n",
    "        \n",
    "        # Handle missing dates\n",
    "        df = df.dropna(subset=['Date'])\n",
    "        \n",
    "        # Ensure Modal Price is numeric\n",
    "        df['Modal Price (Rs./kg)'] = pd.to_numeric(df['Modal Price (Rs./kg)'], errors='coerce')\n",
    "        \n",
    "        # Remove rows with missing modal prices\n",
    "        df = df.dropna(subset=['Modal Price (Rs./kg)'])\n",
    "        \n",
    "        # Rename columns for consistency\n",
    "        df = df.rename(columns={\n",
    "            'District Name': 'District_Name',\n",
    "            'Market Name': 'Market_Name', \n",
    "            'Modal Price (Rs./kg)': 'Modal_Price',\n",
    "            'Min Price (Rs./Quintal)': 'Min_Price_Quintal',\n",
    "            'Max Price (Rs./Quintal)': 'Max_Price_Quintal',\n",
    "            'Min Price ': 'Min_Price',\n",
    "            'Max price': 'Max_Price'\n",
    "        })\n",
    "        \n",
    "        # Remove outliers using IQR method\n",
    "        numeric_columns = ['Modal_Price', 'Min_Price', 'Max_Price']\n",
    "        for col in numeric_columns:\n",
    "            if col in df.columns:\n",
    "                Q1 = df[col].quantile(0.25)\n",
    "                Q3 = df[col].quantile(0.75)\n",
    "                IQR = Q3 - Q1\n",
    "                lower_bound = Q1 - 1.5 * IQR\n",
    "                upper_bound = Q3 + 1.5 * IQR\n",
    "                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "        \n",
    "        # Sort by date\n",
    "        df = df.sort_values('Date').reset_index(drop=True)\n",
    "        \n",
    "        print(f\"‚úÖ Data preprocessed: {len(df)} records after cleaning\")\n",
    "        print(f\"üìà Date range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "        print(f\"üè∑Ô∏è  Commodities: {df['Commodity'].nunique()} unique commodities\")\n",
    "        print(f\"üè¢ Districts: {df['District_Name'].nunique()} unique districts\")\n",
    "        print(f\"üìä Commodities list: {', '.join(df['Commodity'].unique()[:10])}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading data: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load your data\n",
    "df = load_and_preprocess_data('demo1.csv')\n",
    "\n",
    "if df is not None:\n",
    "    print(\"\\nüéâ Data loading completed successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå Please check your file path and data format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a117e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß Creating features...\n",
      "‚úÖ Feature engineering completed!\n",
      "üìä Total features: 45\n",
      "üìà Sample features: ['Modal_Price_Rolling_Min_14', 'Modal_Price_Rolling_Max_14', 'Modal_Price_Rolling_Mean_30', 'Modal_Price_Rolling_Std_30', 'Modal_Price_Rolling_Min_30', 'Modal_Price_Rolling_Max_30', 'Price_Change_1D', 'Price_Change_7D', 'Price_Pct_Change_1D', 'Price_Pct_Change_7D']\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: ADVANCED FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "\n",
    "def create_time_features(df):\n",
    "    \"\"\"Create comprehensive time-based features\"\"\"\n",
    "    df_featured = df.copy()\n",
    "    \n",
    "    # Basic time features\n",
    "    df_featured['Year'] = df_featured['Date'].dt.year\n",
    "    df_featured['Month'] = df_featured['Date'].dt.month\n",
    "    df_featured['Day'] = df_featured['Date'].dt.day\n",
    "    df_featured['DayOfWeek'] = df_featured['Date'].dt.dayofweek\n",
    "    df_featured['DayOfYear'] = df_featured['Date'].dt.dayofyear\n",
    "    df_featured['WeekOfYear'] = df_featured['Date'].dt.isocalendar().week\n",
    "    df_featured['Quarter'] = df_featured['Date'].dt.quarter\n",
    "    \n",
    "    # Seasonal features\n",
    "    df_featured['IsSummer'] = df_featured['Month'].isin([4, 5, 6]).astype(int)\n",
    "    df_featured['IsMonsoon'] = df_featured['Month'].isin([7, 8, 9]).astype(int)\n",
    "    df_featured['IsWinter'] = df_featured['Month'].isin([12, 1, 2]).astype(int)\n",
    "    df_featured['IsHarvestSeason'] = df_featured['Month'].isin([10, 11, 12, 1]).astype(int)\n",
    "    \n",
    "    return df_featured\n",
    "\n",
    "def create_price_features(df):\n",
    "    \"\"\"Create price-based features for each commodity\"\"\"\n",
    "    df_featured = df.copy()\n",
    "    \n",
    "    # Sort by commodity and date\n",
    "    df_featured = df_featured.sort_values(['Commodity', 'Date']).reset_index(drop=True)\n",
    "    \n",
    "    for commodity in df_featured['Commodity'].unique():\n",
    "        mask = df_featured['Commodity'] == commodity\n",
    "        \n",
    "        # Lag features (previous day prices)\n",
    "        for lag in [1, 2, 3, 7, 14]:\n",
    "            df_featured.loc[mask, f'Modal_Price_Lag_{lag}'] = df_featured.loc[mask, 'Modal_Price'].shift(lag)\n",
    "        \n",
    "        # Rolling statistics\n",
    "        for window in [7, 14, 30]:\n",
    "            df_featured.loc[mask, f'Modal_Price_Rolling_Mean_{window}'] = df_featured.loc[mask, 'Modal_Price'].rolling(window=window).mean()\n",
    "            df_featured.loc[mask, f'Modal_Price_Rolling_Std_{window}'] = df_featured.loc[mask, 'Modal_Price'].rolling(window=window).std()\n",
    "            df_featured.loc[mask, f'Modal_Price_Rolling_Min_{window}'] = df_featured.loc[mask, 'Modal_Price'].rolling(window=window).min()\n",
    "            df_featured.loc[mask, f'Modal_Price_Rolling_Max_{window}'] = df_featured.loc[mask, 'Modal_Price'].rolling(window=window).max()\n",
    "        \n",
    "        # Price changes\n",
    "        df_featured.loc[mask, 'Price_Change_1D'] = df_featured.loc[mask, 'Modal_Price'].diff()\n",
    "        df_featured.loc[mask, 'Price_Change_7D'] = df_featured.loc[mask, 'Modal_Price'].diff(7)\n",
    "        df_featured.loc[mask, 'Price_Pct_Change_1D'] = df_featured.loc[mask, 'Modal_Price'].pct_change()\n",
    "        df_featured.loc[mask, 'Price_Pct_Change_7D'] = df_featured.loc[mask, 'Modal_Price'].pct_change(7)\n",
    "    \n",
    "    return df_featured\n",
    "\n",
    "# Apply feature engineering\n",
    "if df is not None:\n",
    "    print(\"\\nüîß Creating features...\")\n",
    "    df_featured = create_time_features(df)\n",
    "    df_featured = create_price_features(df_featured)\n",
    "    \n",
    "    print(\"‚úÖ Feature engineering completed!\")\n",
    "    print(f\"üìä Total features: {df_featured.shape[1]}\")\n",
    "    print(f\"üìà Sample features: {list(df_featured.columns[-10:])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b13df18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Prediction framework initialized!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 4: COMPREHENSIVE PREDICTION MODEL FRAMEWORK\n",
    "# ============================================================================\n",
    "\n",
    "class CommodityPricePredictor:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.scalers = {}\n",
    "        self.feature_columns = []\n",
    "        \n",
    "    def prepare_features(self, df, commodity):\n",
    "        \"\"\"Prepare features for modeling\"\"\"\n",
    "        # Filter for specific commodity\n",
    "        commodity_data = df[df['Commodity'] == commodity].copy()\n",
    "        \n",
    "        if len(commodity_data) < 50:  # Minimum data requirement\n",
    "            return None, None, None, \"Insufficient data for modeling\"\n",
    "        \n",
    "        # Remove rows with NaN values created by feature engineering\n",
    "        commodity_data = commodity_data.dropna()\n",
    "        \n",
    "        if len(commodity_data) < 30:\n",
    "            return None, None, None, \"Insufficient data after cleaning\"\n",
    "        \n",
    "        # Define feature columns (exclude target and identification columns)\n",
    "        exclude_cols = ['Date', 'Commodity', 'District_Name', 'Market_Name', 'Variety', 'Grade', \n",
    "                       'Min_Price', 'Max_Price', 'Modal_Price', 'Min_Price_Quintal', 'Max_Price_Quintal',\n",
    "                       'Sl no.', 'Price Date']\n",
    "        \n",
    "        self.feature_columns = [col for col in commodity_data.columns if col not in exclude_cols]\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = commodity_data[self.feature_columns]\n",
    "        y = commodity_data['Modal_Price']\n",
    "        dates = commodity_data['Date']\n",
    "        \n",
    "        return X, y, dates, None\n",
    "    \n",
    "    def train_arima_model(self, y, commodity):\n",
    "        \"\"\"Train ARIMA model\"\"\"\n",
    "        try:\n",
    "            # Use only recent data for ARIMA (last 100 points)\n",
    "            y_recent = y.tail(min(100, len(y)))\n",
    "            \n",
    "            # Check stationarity\n",
    "            adf_result = adfuller(y_recent.dropna())\n",
    "            \n",
    "            if adf_result[1] > 0.05:  # Non-stationary\n",
    "                # Difference the series\n",
    "                y_diff = y_recent.diff().dropna()\n",
    "                if len(y_diff) > 10:\n",
    "                    model = ARIMA(y_diff, order=(1, 1, 1))\n",
    "                else:\n",
    "                    model = ARIMA(y_recent, order=(1, 0, 1))\n",
    "            else:\n",
    "                model = ARIMA(y_recent, order=(1, 0, 1))\n",
    "            \n",
    "            fitted_model = model.fit()\n",
    "            self.models[f'{commodity}_arima'] = fitted_model\n",
    "            return fitted_model, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None, f\"ARIMA modeling failed: {str(e)}\"\n",
    "    \n",
    "    def train_ml_models(self, X, y, commodity):\n",
    "        \"\"\"Train multiple ML models\"\"\"\n",
    "        try:\n",
    "            # Split data\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, shuffle=False, random_state=42\n",
    "            )\n",
    "            \n",
    "            # Scale features\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            self.scalers[commodity] = scaler\n",
    "            \n",
    "            models_to_train = {\n",
    "                'RandomForest': RandomForestRegressor(n_estimators=50, random_state=42, max_depth=10),\n",
    "                'XGBoost': xgb.XGBRegressor(n_estimators=50, random_state=42, max_depth=6)\n",
    "            }\n",
    "            \n",
    "            model_scores = {}\n",
    "            \n",
    "            for model_name, model in models_to_train.items():\n",
    "                try:\n",
    "                    # Train model\n",
    "                    if model_name == 'XGBoost':\n",
    "                        model.fit(X_train_scaled, y_train)\n",
    "                        y_pred = model.predict(X_test_scaled)\n",
    "                    else:\n",
    "                        model.fit(X_train, y_train)\n",
    "                        y_pred = model.predict(X_test)\n",
    "                    \n",
    "                    # Calculate metrics\n",
    "                    mae = mean_absolute_error(y_test, y_pred)\n",
    "                    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "                    r2 = r2_score(y_test, y_pred)\n",
    "                    \n",
    "                    model_scores[model_name] = {\n",
    "                        'model': model,\n",
    "                        'mae': mae,\n",
    "                        'rmse': rmse,\n",
    "                        'r2': r2,\n",
    "                        'score': r2  # Use R2 as primary metric\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to train {model_name}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            if not model_scores:\n",
    "                return None, \"All ML models failed\"\n",
    "            \n",
    "            # Select best model\n",
    "            best_model_name = max(model_scores, key=lambda x: model_scores[x]['score'])\n",
    "            best_model_info = model_scores[best_model_name]\n",
    "            \n",
    "            self.models[f'{commodity}_ml'] = {\n",
    "                'model': best_model_info['model'],\n",
    "                'type': best_model_name,\n",
    "                'metrics': best_model_info\n",
    "            }\n",
    "            \n",
    "            return best_model_info, None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None, f\"ML modeling failed: {str(e)}\"\n",
    "    \n",
    "    def train_commodity_model(self, df, commodity):\n",
    "        \"\"\"Train complete model for a commodity\"\"\"\n",
    "        print(f\"\\nüîÑ Training model for {commodity}...\")\n",
    "        \n",
    "        # Prepare features\n",
    "        X, y, dates, error = self.prepare_features(df, commodity)\n",
    "        if error:\n",
    "            print(f\"‚ùå {error}\")\n",
    "            return error\n",
    "        \n",
    "        # Train ARIMA model\n",
    "        arima_model, arima_error = self.train_arima_model(y, commodity)\n",
    "        \n",
    "        # Train ML models\n",
    "        ml_model, ml_error = self.train_ml_models(X, y, commodity)\n",
    "        \n",
    "        if arima_model is None and ml_model is None:\n",
    "            error_msg = f\"Both ARIMA and ML modeling failed for {commodity}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            return error_msg\n",
    "        \n",
    "        success_msg = f\"‚úÖ {commodity} model trained successfully!\"\n",
    "        if arima_model: success_msg += \" (ARIMA + ML)\" if ml_model else \" (ARIMA only)\"\n",
    "        elif ml_model: success_msg += \" (ML only)\"\n",
    "        \n",
    "        print(success_msg)\n",
    "        return None\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = CommodityPricePredictor()\n",
    "\n",
    "print(\"‚úÖ Prediction framework initialized!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d7339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 28-day prediction system ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: 28-DAY PREDICTION SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "def predict_future_prices(commodity, days_ahead=28):\n",
    "    \"\"\"Predict future prices for specified days\"\"\"\n",
    "    try:\n",
    "        # Get commodity data\n",
    "        commodity_data = df_featured[df_featured['Commodity'] == commodity].copy()\n",
    "        if len(commodity_data) == 0:\n",
    "            return f\"No data available for {commodity}\"\n",
    "        \n",
    "        # Sort by date\n",
    "        commodity_data = commodity_data.sort_values('Date').reset_index(drop=True)\n",
    "        \n",
    "        # Get last known date and price\n",
    "        last_date = commodity_data['Date'].max()\n",
    "        last_price = commodity_data[commodity_data['Date'] == last_date]['Modal_Price'].iloc[-1]\n",
    "        \n",
    "        # Generate future dates\n",
    "        future_dates = [last_date + timedelta(days=i) for i in range(1, days_ahead + 1)]\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # Try ARIMA first\n",
    "        if f'{commodity}_arima' in predictor.models:\n",
    "            try:\n",
    "                arima_model = predictor.models[f'{commodity}_arima']\n",
    "                forecast = arima_model.forecast(steps=days_ahead)\n",
    "                \n",
    "                # ARIMA might predict differences, so we need to convert back to levels\n",
    "                if hasattr(forecast, '__len__') and len(forecast) == days_ahead:\n",
    "                    # If ARIMA was trained on differences, convert back to levels\n",
    "                    predictions = []\n",
    "                    current_price = last_price\n",
    "                    for i, diff in enumerate(forecast):\n",
    "                        if abs(diff) < last_price:  # Reasonable difference\n",
    "                            current_price += diff\n",
    "                        else:\n",
    "                            # Use simple trend if difference is too large\n",
    "                            current_price *= (1 + np.random.normal(0, 0.02))\n",
    "                        predictions.append(max(current_price, 0.1))  # Ensure positive prices\n",
    "                else:\n",
    "                    predictions = None\n",
    "            except Exception as e:\n",
    "                print(f\"ARIMA prediction failed for {commodity}: {e}\")\n",
    "                predictions = None\n",
    "        \n",
    "        # Use ML model if ARIMA fails or unavailable\n",
    "        if not predictions and f'{commodity}_ml' in predictor.models:\n",
    "            try:\n",
    "                ml_info = predictor.models[f'{commodity}_ml']\n",
    "                model = ml_info['model']\n",
    "                \n",
    "                # Get last row for feature generation\n",
    "                last_row = commodity_data.iloc[-1].copy()\n",
    "                predictions = []\n",
    "                \n",
    "                for i in range(days_ahead):\n",
    "                    # Create feature row for prediction\n",
    "                    future_date = future_dates[i]\n",
    "                    \n",
    "                    # Update time features\n",
    "                    last_row['Year'] = future_date.year\n",
    "                    last_row['Month'] = future_date.month\n",
    "                    last_row['Day'] = future_date.day\n",
    "                    last_row['DayOfWeek'] = future_date.weekday()\n",
    "                    last_row['DayOfYear'] = future_date.timetuple().tm_yday\n",
    "                    last_row['WeekOfYear'] = future_date.isocalendar()[1]\n",
    "                    last_row['Quarter'] = (future_date.month - 1) // 3 + 1\n",
    "                    \n",
    "                    # Update seasonal features\n",
    "                    last_row['IsSummer'] = 1 if future_date.month in [4, 5, 6] else 0\n",
    "                    last_row['IsMonsoon'] = 1 if future_date.month in [7, 8, 9] else 0\n",
    "                    last_row['IsWinter'] = 1 if future_date.month in [12, 1, 2] else 0\n",
    "                    last_row['IsHarvestSeason'] = 1 if future_date.month in [10, 11, 12, 1] else 0\n",
    "                    \n",
    "                    # Prepare feature vector\n",
    "                    X_pred = last_row[predictor.feature_columns].values.reshape(1, -1)\n",
    "                    \n",
    "                    # Handle scaling if required\n",
    "                    if commodity in predictor.scalers and ml_info['type'] == 'XGBoost':\n",
    "                        X_pred = predictor.scalers[commodity].transform(X_pred)\n",
    "                    \n",
    "                    # Predict\n",
    "                    pred_price = model.predict(X_pred)[0]\n",
    "                    predictions.append(max(pred_price, 0.1))  # Ensure positive prices\n",
    "                    \n",
    "                    # Update lag features for next iteration\n",
    "                    last_row['Modal_Price'] = pred_price\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"ML prediction failed for {commodity}: {e}\")\n",
    "                predictions = None\n",
    "        \n",
    "        # Fallback: Simple trend-based prediction\n",
    "        if not predictions:\n",
    "            recent_prices = commodity_data.tail(30)['Modal_Price'].values\n",
    "            if len(recent_prices) > 1:\n",
    "                # Calculate trend\n",
    "                trend = (recent_prices[-1] - recent_prices[0]) / len(recent_prices)\n",
    "                predictions = []\n",
    "                current_price = last_price\n",
    "                \n",
    "                for i in range(days_ahead):\n",
    "                    # Add trend + some noise\n",
    "                    current_price += trend + np.random.normal(0, abs(trend) * 0.1)\n",
    "                    predictions.append(max(current_price, 0.1))\n",
    "            else:\n",
    "                return f\"Insufficient data for prediction: {commodity}\"\n",
    "        \n",
    "        if not predictions:\n",
    "            return f\"No model available for {commodity}\"\n",
    "        \n",
    "        # Create results DataFrame\n",
    "        results_df = pd.DataFrame({\n",
    "            'Date': future_dates,\n",
    "            'Predicted_Price': predictions,\n",
    "            'Commodity': commodity\n",
    "        })\n",
    "        \n",
    "        return results_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Prediction failed: {str(e)}\"\n",
    "\n",
    "def predict_weekly_prices(commodity, weeks=4):\n",
    "    \"\"\"Predict and organize prices by weeks\"\"\"\n",
    "    print(f\"\\nüìä Generating {weeks}-week prediction for {commodity}...\")\n",
    "    \n",
    "    total_days = weeks * 7\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = predict_future_prices(commodity, days_ahead=total_days)\n",
    "    \n",
    "    if isinstance(predictions, str):\n",
    "        print(f\"‚ùå {predictions}\")\n",
    "        return predictions\n",
    "    \n",
    "    # Organize by weeks\n",
    "    weekly_predictions = {}\n",
    "    \n",
    "    for week in range(1, weeks + 1):\n",
    "        start_idx = (week - 1) * 7\n",
    "        end_idx = week * 7\n",
    "        \n",
    "        week_data = predictions.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        # Calculate week statistics\n",
    "        avg_price = week_data['Predicted_Price'].mean()\n",
    "        min_price = week_data['Predicted_Price'].min()\n",
    "        max_price = week_data['Predicted_Price'].max()\n",
    "        \n",
    "        # Calculate trend\n",
    "        first_price = week_data['Predicted_Price'].iloc[0]\n",
    "        last_price = week_data['Predicted_Price'].iloc[-1]\n",
    "        price_change = last_price - first_price\n",
    "        price_change_pct = (price_change / first_price) * 100\n",
    "        \n",
    "        # Determine trend direction\n",
    "        if price_change_pct > 2:\n",
    "            trend = \"‚Üó Increasing\"\n",
    "        elif price_change_pct < -2:\n",
    "            trend = \"‚Üò Decreasing\"\n",
    "        else:\n",
    "            trend = \"‚Üí Stable\"\n",
    "        \n",
    "        weekly_predictions[f'Week_{week}'] = {\n",
    "            'dates': week_data['Date'].tolist(),\n",
    "            'prices': week_data['Predicted_Price'].tolist(),\n",
    "            'avg_price': round(avg_price, 2),\n",
    "            'min_price': round(min_price, 2),\n",
    "            'max_price': round(max_price, 2),\n",
    "            'price_change': round(price_change, 2),\n",
    "            'price_change_pct': round(price_change_pct, 2),\n",
    "            'trend': trend,\n",
    "            'date_range': f\"{week_data['Date'].iloc[0].strftime('%b %d')} - {week_data['Date'].iloc[-1].strftime('%b %d')}\"\n",
    "        }\n",
    "    \n",
    "    return weekly_predictions\n",
    "\n",
    "print(\"‚úÖ 28-day prediction system ready!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "650bd3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Market intervention analysis system ready!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: MARKET INTERVENTION ANALYSIS SYSTEM\n",
    "# ============================================================================\n",
    "\n",
    "def market_intervention_analysis(commodity, price_increase_threshold=20):\n",
    "    \"\"\"Analyze if market intervention is needed\"\"\"\n",
    "    print(f\"\\nüîç Analyzing market intervention needs for {commodity}...\")\n",
    "    \n",
    "    # Get recent price data (last 30 days)\n",
    "    recent_data = df_featured[df_featured['Commodity'] == commodity].tail(30)\n",
    "    if len(recent_data) == 0:\n",
    "        return f\"No data available for {commodity}\"\n",
    "    \n",
    "    current_avg_price = recent_data['Modal_Price'].mean()\n",
    "    \n",
    "    # Get 28-day predictions\n",
    "    future_prices = predict_future_prices(commodity, days_ahead=28)\n",
    "    \n",
    "    if isinstance(future_prices, str):\n",
    "        return f\"Cannot analyze {commodity}: {future_prices}\"\n",
    "    \n",
    "    # Calculate metrics\n",
    "    max_predicted_price = future_prices['Predicted_Price'].max()\n",
    "    avg_predicted_price = future_prices['Predicted_Price'].mean()\n",
    "    min_predicted_price = future_prices['Predicted_Price'].min()\n",
    "    \n",
    "    # Calculate percentage changes\n",
    "    max_increase_pct = ((max_predicted_price - current_avg_price) / current_avg_price) * 100\n",
    "    avg_increase_pct = ((avg_predicted_price - current_avg_price) / current_avg_price) * 100\n",
    "    \n",
    "    # Determine intervention need\n",
    "    intervention_needed = max_increase_pct > price_increase_threshold\n",
    "    \n",
    "    # Determine urgency level\n",
    "    if max_increase_pct > 30:\n",
    "        urgency = \"üî¥ HIGH\"\n",
    "        recommendation = \"IMMEDIATE BUFFER STOCK RELEASE\"\n",
    "    elif max_increase_pct > 20:\n",
    "        urgency = \"üü° MEDIUM\"\n",
    "        recommendation = \"PREPARE BUFFER STOCK RELEASE\"\n",
    "    else:\n",
    "        urgency = \"üü¢ LOW\"\n",
    "        recommendation = \"MONITOR PRICES CLOSELY\"\n",
    "    \n",
    "    # Calculate volatility\n",
    "    price_volatility = future_prices['Predicted_Price'].std()\n",
    "    volatility_pct = (price_volatility / current_avg_price) * 100\n",
    "    \n",
    "    return {\n",
    "        'Commodity': commodity,\n",
    "        'Current_Avg_Price': round(current_avg_price, 2),\n",
    "        'Predicted_Max_Price': round(max_predicted_price, 2),\n",
    "        'Predicted_Avg_Price': round(avg_predicted_price, 2),\n",
    "        'Predicted_Min_Price': round(min_predicted_price, 2),\n",
    "        'Max_Price_Increase_Pct': round(max_increase_pct, 2),\n",
    "        'Avg_Price_Increase_Pct': round(avg_increase_pct, 2),\n",
    "        'Price_Volatility': round(volatility_pct, 2),\n",
    "        'Intervention_Needed': intervention_needed,\n",
    "        'Urgency_Level': urgency,\n",
    "        'Recommendation': recommendation,\n",
    "        'Districts_Affected': df_featured[df_featured['Commodity'] == commodity]['District_Name'].nunique(),\n",
    "        'Risk_Score': round(max_increase_pct + volatility_pct, 2)\n",
    "    }\n",
    "\n",
    "def comprehensive_market_analysis():\n",
    "    \"\"\"Analyze all commodities for intervention needs\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üö® COMPREHENSIVE MARKET INTERVENTION ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Get top commodities by data availability\n",
    "    commodity_counts = df_featured['Commodity'].value_counts()\n",
    "    top_commodities = commodity_counts.head(8).index.tolist()  # Analyze top 8 commodities\n",
    "    \n",
    "    print(f\"üìä Analyzing {len(top_commodities)} commodities with sufficient data...\")\n",
    "    print(f\"Selected commodities: {', '.join(top_commodities)}\")\n",
    "    \n",
    "    interventions_needed = []\n",
    "    stable_commodities = []\n",
    "    failed_analyses = []\n",
    "    \n",
    "    for commodity in top_commodities:\n",
    "        try:\n",
    "            analysis = market_intervention_analysis(commodity)\n",
    "            if isinstance(analysis, dict):\n",
    "                if analysis['Intervention_Needed']:\n",
    "                    interventions_needed.append(analysis)\n",
    "                else:\n",
    "                    stable_commodities.append(analysis)\n",
    "            else:\n",
    "                failed_analyses.append({'commodity': commodity, 'error': analysis})\n",
    "        except Exception as e:\n",
    "            failed_analyses.append({'commodity': commodity, 'error': str(e)})\n",
    "    \n",
    "    # Sort interventions by risk score (descending)\n",
    "    interventions_needed.sort(key=lambda x: x['Risk_Score'], reverse=True)\n",
    "    \n",
    "    return interventions_needed, stable_commodities, failed_analyses\n",
    "\n",
    "def display_intervention_dashboard(interventions_needed, stable_commodities, failed_analyses):\n",
    "    \"\"\"Display comprehensive intervention analysis dashboard\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"üìä MARKET INTERVENTION DASHBOARD\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_analyzed = len(interventions_needed) + len(stable_commodities)\n",
    "    \n",
    "    print(f\"\\nüìà ANALYSIS SUMMARY:\")\n",
    "    print(f\"‚Ä¢ Total commodities analyzed: {total_analyzed}\")\n",
    "    print(f\"‚Ä¢ Interventions needed: {len(interventions_needed)}\")\n",
    "    print(f\"‚Ä¢ Stable commodities: {len(stable_commodities)}\")\n",
    "    print(f\"‚Ä¢ Analysis failures: {len(failed_analyses)}\")\n",
    "    \n",
    "    # High-risk commodities\n",
    "    if interventions_needed:\n",
    "        print(f\"\\nüö® COMMODITIES REQUIRING INTERVENTION:\")\n",
    "        print(\"-\" * 120)\n",
    "        print(f\"{'Commodity':<15} {'Current ‚Çπ':<12} {'Max Pred ‚Çπ':<12} {'Increase %':<12} {'Volatility %':<12} {'Risk Score':<12} {'Urgency':<15}\")\n",
    "        print(\"-\" * 120)\n",
    "        \n",
    "        for item in interventions_needed:\n",
    "            print(f\"{item['Commodity']:<15} \"\n",
    "                  f\"‚Çπ{item['Current_Avg_Price']:<11.2f} \"\n",
    "                  f\"‚Çπ{item['Predicted_Max_Price']:<11.2f} \"\n",
    "                  f\"{item['Max_Price_Increase_Pct']:<11.1f}% \"\n",
    "                  f\"{item['Price_Volatility']:<11.1f}% \"\n",
    "                  f\"{item['Risk_Score']:<11.1f} \"\n",
    "                  f\"{item['Urgency_Level']:<15}\")\n",
    "        \n",
    "        # Top 3 high-risk commodities\n",
    "        print(f\"\\nüî• TOP 3 HIGH-RISK COMMODITIES:\")\n",
    "        for i, item in enumerate(interventions_needed[:3], 1):\n",
    "            print(f\"{i}. {item['Commodity']}: {item['Max_Price_Increase_Pct']:.1f}% increase predicted\")\n",
    "            print(f\"   ‚Üí {item['Recommendation']}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n‚úÖ No commodities require immediate intervention!\")\n",
    "    \n",
    "    # Stable commodities\n",
    "    if stable_commodities:\n",
    "        print(f\"\\nüíö STABLE COMMODITIES ({len(stable_commodities)}):\")\n",
    "        stable_names = [item['Commodity'] for item in stable_commodities[:6]]\n",
    "        print(\"   \" + \", \".join(stable_names))\n",
    "        if len(stable_commodities) > 6:\n",
    "            print(f\"   ... and {len(stable_commodities) - 6} more\")\n",
    "    \n",
    "    # Failed analyses\n",
    "    if failed_analyses:\n",
    "        print(f\"\\n‚ö†Ô∏è  ANALYSIS FAILURES ({len(failed_analyses)}):\")\n",
    "        for failure in failed_analyses[:3]:\n",
    "            print(f\"   ‚Ä¢ {failure['commodity']}: {failure['error']}\")\n",
    "\n",
    "print(\"‚úÖ Market intervention analysis system ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d613ff19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ STARTING COMPLETE 28-DAY COMMODITY PRICE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "üìã Selected commodities for analysis: Tomato, Onion, Cabbage, Potato, Brinjal\n",
      "\n",
      "==================================================\n",
      "üéØ STEP 1: TRAINING PREDICTION MODELS\n",
      "==================================================\n",
      "\n",
      "üîÑ Training model for Tomato...\n",
      "‚úÖ Tomato model trained successfully! (ARIMA + ML)\n",
      "\n",
      "üîÑ Training model for Onion...\n",
      "‚úÖ Onion model trained successfully! (ARIMA + ML)\n",
      "\n",
      "üîÑ Training model for Cabbage...\n",
      "‚úÖ Cabbage model trained successfully! (ARIMA + ML)\n",
      "\n",
      "üîÑ Training model for Potato...\n",
      "‚úÖ Potato model trained successfully! (ARIMA + ML)\n",
      "\n",
      "üîÑ Training model for Brinjal...\n",
      "‚úÖ Brinjal model trained successfully! (ARIMA + ML)\n",
      "\n",
      "==================================================\n",
      "üìä STEP 2: GENERATING 28-DAY PREDICTIONS\n",
      "==================================================\n",
      "\n",
      "üìä Generating 4-week prediction for Tomato...\n",
      "\n",
      "üìä Generating 4-week prediction for Onion...\n",
      "\n",
      "üìä Generating 4-week prediction for Cabbage...\n",
      "\n",
      "üìä Generating 4-week prediction for Potato...\n",
      "\n",
      "üìä Generating 4-week prediction for Brinjal...\n",
      "\n",
      "==================================================\n",
      "üîç STEP 3: MARKET INTERVENTION ANALYSIS\n",
      "==================================================\n",
      "\n",
      "================================================================================\n",
      "üö® COMPREHENSIVE MARKET INTERVENTION ANALYSIS\n",
      "================================================================================\n",
      "üìä Analyzing 8 commodities with sufficient data...\n",
      "Selected commodities: Tomato, Onion, Cabbage, Potato, Brinjal, Papaya, Guava, Banana\n",
      "\n",
      "üîç Analyzing market intervention needs for Tomato...\n",
      "\n",
      "üîç Analyzing market intervention needs for Onion...\n",
      "\n",
      "üîç Analyzing market intervention needs for Cabbage...\n",
      "\n",
      "üîç Analyzing market intervention needs for Potato...\n",
      "\n",
      "üîç Analyzing market intervention needs for Brinjal...\n",
      "\n",
      "üîç Analyzing market intervention needs for Papaya...\n",
      "\n",
      "üîç Analyzing market intervention needs for Guava...\n",
      "\n",
      "üîç Analyzing market intervention needs for Banana...\n",
      "\n",
      "==================================================\n",
      "üìà STEP 4: COMPREHENSIVE RESULTS\n",
      "==================================================\n",
      "\n",
      "üè∑Ô∏è  TOMATO - 28-DAY WEEK-WISE PREDICTIONS:\n",
      "--------------------------------------------------------------------------------\n",
      "Week     Date Range           Avg Price    Min-Max            Trend           Change %\n",
      "--------------------------------------------------------------------------------\n",
      "Week_1   Jul 28 - Aug 03      ‚Çπ17.94       ‚Çπ17-‚Çπ18            ‚Üí Stable        -1.6%\n",
      "Week_2   Aug 04 - Aug 10      ‚Çπ16.82       ‚Çπ16-‚Çπ18            ‚Üò Decreasing    -7.2%\n",
      "Week_3   Aug 11 - Aug 17      ‚Çπ16.40       ‚Çπ16-‚Çπ17            ‚Üò Decreasing    -3.5%\n",
      "Week_4   Aug 18 - Aug 24      ‚Çπ16.04       ‚Çπ16-‚Çπ16            ‚Üí Stable        -0.2%\n",
      "\n",
      "üè∑Ô∏è  ONION - 28-DAY WEEK-WISE PREDICTIONS:\n",
      "--------------------------------------------------------------------------------\n",
      "Week     Date Range           Avg Price    Min-Max            Trend           Change %\n",
      "--------------------------------------------------------------------------------\n",
      "Week_1   Jul 28 - Aug 03      ‚Çπ11.55       ‚Çπ11-‚Çπ12            ‚Üó Increasing    +6.9%\n",
      "Week_2   Aug 04 - Aug 10      ‚Çπ11.37       ‚Çπ11-‚Çπ12            ‚Üò Decreasing    -9.4%\n",
      "Week_3   Aug 11 - Aug 17      ‚Çπ10.70       ‚Çπ11-‚Çπ11            ‚Üí Stable        -1.5%\n",
      "Week_4   Aug 18 - Aug 24      ‚Çπ11.04       ‚Çπ11-‚Çπ12            ‚Üó Increasing    +7.0%\n",
      "\n",
      "üè∑Ô∏è  CABBAGE - 28-DAY WEEK-WISE PREDICTIONS:\n",
      "--------------------------------------------------------------------------------\n",
      "Week     Date Range           Avg Price    Min-Max            Trend           Change %\n",
      "--------------------------------------------------------------------------------\n",
      "Week_1   Jul 28 - Aug 03      ‚Çπ8.66        ‚Çπ8-‚Çπ9              ‚Üò Decreasing    -7.6%\n",
      "Week_2   Aug 04 - Aug 10      ‚Çπ8.01        ‚Çπ8-‚Çπ8              ‚Üò Decreasing    -2.0%\n",
      "Week_3   Aug 11 - Aug 17      ‚Çπ7.80        ‚Çπ8-‚Çπ8              ‚Üí Stable        -0.7%\n",
      "Week_4   Aug 18 - Aug 24      ‚Çπ8.13        ‚Çπ8-‚Çπ8              ‚Üó Increasing    +3.6%\n",
      "\n",
      "üè∑Ô∏è  POTATO - 28-DAY WEEK-WISE PREDICTIONS:\n",
      "--------------------------------------------------------------------------------\n",
      "Week     Date Range           Avg Price    Min-Max            Trend           Change %\n",
      "--------------------------------------------------------------------------------\n",
      "Week_1   Jul 28 - Aug 03      ‚Çπ14.58       ‚Çπ14-‚Çπ15            ‚Üí Stable        -1.6%\n",
      "Week_2   Aug 04 - Aug 10      ‚Çπ14.54       ‚Çπ15-‚Çπ15            ‚Üí Stable        -0.1%\n",
      "Week_3   Aug 11 - Aug 17      ‚Çπ14.52       ‚Çπ15-‚Çπ15            ‚Üí Stable        -0.1%\n",
      "Week_4   Aug 18 - Aug 24      ‚Çπ14.51       ‚Çπ14-‚Çπ15            ‚Üí Stable        -0.1%\n",
      "\n",
      "üè∑Ô∏è  BRINJAL - 28-DAY WEEK-WISE PREDICTIONS:\n",
      "--------------------------------------------------------------------------------\n",
      "Week     Date Range           Avg Price    Min-Max            Trend           Change %\n",
      "--------------------------------------------------------------------------------\n",
      "Week_1   Jul 28 - Aug 03      ‚Çπ15.09       ‚Çπ15-‚Çπ16            ‚Üò Decreasing    -2.9%\n",
      "Week_2   Aug 04 - Aug 10      ‚Çπ14.31       ‚Çπ14-‚Çπ15            ‚Üò Decreasing    -4.8%\n",
      "Week_3   Aug 11 - Aug 17      ‚Çπ13.50       ‚Çπ13-‚Çπ14            ‚Üò Decreasing    -5.0%\n",
      "Week_4   Aug 18 - Aug 24      ‚Çπ12.70       ‚Çπ12-‚Çπ13            ‚Üò Decreasing    -5.3%\n",
      "\n",
      "====================================================================================================\n",
      "üìä MARKET INTERVENTION DASHBOARD\n",
      "====================================================================================================\n",
      "\n",
      "üìà ANALYSIS SUMMARY:\n",
      "‚Ä¢ Total commodities analyzed: 8\n",
      "‚Ä¢ Interventions needed: 2\n",
      "‚Ä¢ Stable commodities: 6\n",
      "‚Ä¢ Analysis failures: 0\n",
      "\n",
      "üö® COMMODITIES REQUIRING INTERVENTION:\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Commodity       Current ‚Çπ    Max Pred ‚Çπ   Increase %   Volatility % Risk Score   Urgency        \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "Banana          ‚Çπ12.20       ‚Çπ23.90       95.9       % 21.6       % 117.5       üî¥ HIGH         \n",
      "Papaya          ‚Çπ15.35       ‚Çπ20.74       35.1       % 7.0        % 42.2        üî¥ HIGH         \n",
      "\n",
      "üî• TOP 3 HIGH-RISK COMMODITIES:\n",
      "1. Banana: 95.9% increase predicted\n",
      "   ‚Üí IMMEDIATE BUFFER STOCK RELEASE\n",
      "2. Papaya: 35.1% increase predicted\n",
      "   ‚Üí IMMEDIATE BUFFER STOCK RELEASE\n",
      "\n",
      "üíö STABLE COMMODITIES (6):\n",
      "   Tomato, Onion, Cabbage, Potato, Brinjal, Guava\n",
      "\n",
      "‚úÖ ANALYSIS COMPLETED SUCCESSFULLY!\n",
      "üìä Generated predictions for 5 commodities\n",
      "üö® 2 commodities need intervention\n",
      "\n",
      "üìã QUICK SUMMARY:\n",
      "‚Ä¢ Data period: July 27, 2024 to July 27, 2025\n",
      "‚Ä¢ Total records: 10,402\n",
      "‚Ä¢ Commodities: Tomato, Brinjal, Onion, Cabbage, Potato, Banana, Papaya, Guava, Grapes, Apple\n",
      "‚Ä¢ Districts: Nagpur, Nashik, Chattrapati Sambhajinagar, Pune, Mumbai\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: COMPLETE EXECUTION WORKFLOW\n",
    "# ============================================================================\n",
    "\n",
    "def execute_complete_analysis():\n",
    "    \"\"\"Execute the complete 28-day prediction and analysis workflow\"\"\"\n",
    "    \n",
    "    print(\"\\nüöÄ STARTING COMPLETE 28-DAY COMMODITY PRICE ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if df_featured is None:\n",
    "        print(\"‚ùå No data available. Please check your file.\")\n",
    "        return\n",
    "    \n",
    "    # Get commodities with sufficient data (at least 100 records)\n",
    "    commodity_counts = df_featured['Commodity'].value_counts()\n",
    "    selected_commodities = commodity_counts[commodity_counts >= 100].head(5).index.tolist()\n",
    "    \n",
    "    if not selected_commodities:\n",
    "        selected_commodities = commodity_counts.head(3).index.tolist()\n",
    "    \n",
    "    print(f\"\\nüìã Selected commodities for analysis: {', '.join(selected_commodities)}\")\n",
    "    \n",
    "    # Step 1: Train models for all commodities\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"üéØ STEP 1: TRAINING PREDICTION MODELS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    training_results = {}\n",
    "    for commodity in selected_commodities:\n",
    "        error = predictor.train_commodity_model(df_featured, commodity)\n",
    "        training_results[commodity] = \"Success\" if error is None else f\"Failed: {error}\"\n",
    "    \n",
    "    # Step 2: Generate 28-day predictions\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"üìä STEP 2: GENERATING 28-DAY PREDICTIONS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    prediction_results = {}\n",
    "    for commodity in selected_commodities:\n",
    "        if \"Success\" in training_results[commodity]:\n",
    "            weekly_pred = predict_weekly_prices(commodity, weeks=4)\n",
    "            prediction_results[commodity] = weekly_pred\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  Skipping {commodity} due to training failure\")\n",
    "    \n",
    "    # Step 3: Market intervention analysis\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"üîç STEP 3: MARKET INTERVENTION ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    interventions, stable, failures = comprehensive_market_analysis()\n",
    "    \n",
    "    # Step 4: Display results\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"üìà STEP 4: COMPREHENSIVE RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Display predictions for each commodity\n",
    "    for commodity, weekly_data in prediction_results.items():\n",
    "        if isinstance(weekly_data, dict):\n",
    "            print(f\"\\nüè∑Ô∏è  {commodity.upper()} - 28-DAY WEEK-WISE PREDICTIONS:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"{'Week':<8} {'Date Range':<20} {'Avg Price':<12} {'Min-Max':<18} {'Trend':<15} {'Change %'}\")\n",
    "            print(\"-\" * 80)\n",
    "            \n",
    "            for week_name, week_info in weekly_data.items():\n",
    "                min_max = f\"‚Çπ{week_info['min_price']:.0f}-‚Çπ{week_info['max_price']:.0f}\"\n",
    "                print(f\"{week_name:<8} \"\n",
    "                      f\"{week_info['date_range']:<20} \"\n",
    "                      f\"‚Çπ{week_info['avg_price']:<11.2f} \"\n",
    "                      f\"{min_max:<18} \"\n",
    "                      f\"{week_info['trend']:<15} \"\n",
    "                      f\"{week_info['price_change_pct']:+.1f}%\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå {commodity}: {weekly_data}\")\n",
    "    \n",
    "    # Display intervention analysis\n",
    "    display_intervention_dashboard(interventions, stable, failures)\n",
    "    \n",
    "    return prediction_results, interventions, stable\n",
    "\n",
    "# Execute the complete workflow\n",
    "try:\n",
    "    if df_featured is not None:\n",
    "        predictions, interventions, stable_commodities = execute_complete_analysis()\n",
    "        print(f\"\\n‚úÖ ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
    "        print(f\"üìä Generated predictions for {len(predictions)} commodities\")\n",
    "        print(f\"üö® {len(interventions)} commodities need intervention\")\n",
    "        \n",
    "        # Quick summary\n",
    "        print(f\"\\nüìã QUICK SUMMARY:\")\n",
    "        print(f\"‚Ä¢ Data period: {df['Date'].min().strftime('%B %d, %Y')} to {df['Date'].max().strftime('%B %d, %Y')}\")\n",
    "        print(f\"‚Ä¢ Total records: {len(df):,}\")\n",
    "        print(f\"‚Ä¢ Commodities: {', '.join(df['Commodity'].unique())}\")\n",
    "        print(f\"‚Ä¢ Districts: {', '.join(df['District_Name'].unique()[:5])}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Please ensure your CSV file is properly loaded\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ANALYSIS FAILED: {str(e)}\")\n",
    "    print(\"\\nPlease ensure:\")\n",
    "    print(\"1. Your CSV file path is correct\")\n",
    "    print(\"2. Data contains required columns: Date, Commodity, Modal_Price, District_Name\")\n",
    "    print(\"3. Data has sufficient historical records for each commodity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28c235ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Exporting results...\n",
      "‚úÖ Exported Tomato predictions to Tomato_28day_predictions_20250730_230250.csv\n",
      "‚úÖ Exported Onion predictions to Onion_28day_predictions_20250730_230250.csv\n",
      "‚úÖ Exported Cabbage predictions to Cabbage_28day_predictions_20250730_230250.csv\n",
      "‚úÖ Exported Potato predictions to Potato_28day_predictions_20250730_230250.csv\n",
      "‚úÖ Exported Brinjal predictions to Brinjal_28day_predictions_20250730_230250.csv\n",
      "‚úÖ Exported intervention analysis to market_interventions_20250730_230250.csv\n",
      "\n",
      "üìÅ All reports exported with timestamp: 20250730_230250\n",
      "‚ùå Report generation failed: 'charmap' codec can't encode character '\\U0001f4ca' in position 82: character maps to <undefined>\n",
      "\n",
      "üéâ COMPLETE 28-DAY COMMODITY PRICE PREDICTION SYSTEM EXECUTED SUCCESSFULLY!\n",
      "================================================================================\n",
      "‚úÖ All analysis completed\n",
      "üìä Predictions generated for multiple commodities\n",
      "üö® Market intervention recommendations provided\n",
      "üìÅ Results exported to CSV files\n",
      "üìã Summary report generated\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# STEP 8: EXPORT RESULTS AND GENERATE REPORTS\n",
    "# ============================================================================\n",
    "\n",
    "def export_predictions_to_csv():\n",
    "    \"\"\"Export all predictions to CSV files\"\"\"\n",
    "    \n",
    "    from datetime import datetime as dt\n",
    "    timestamp = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    try:\n",
    "        # Export individual commodity predictions\n",
    "        for commodity, weekly_pred in predictions.items():\n",
    "            if isinstance(weekly_pred, dict):\n",
    "                # Create detailed dataframe\n",
    "                export_data = []\n",
    "                \n",
    "                for week_name, week_data in weekly_pred.items():\n",
    "                    for i, (date, price) in enumerate(zip(week_data['dates'], week_data['prices'])):\n",
    "                        export_data.append({\n",
    "                            'Date': date.strftime('%Y-%m-%d'),\n",
    "                            'Commodity': commodity,\n",
    "                            'Week': week_name,\n",
    "                            'Day_in_Week': i + 1,\n",
    "                            'Predicted_Price': round(price, 2),\n",
    "                            'Week_Avg_Price': week_data['avg_price'],\n",
    "                            'Week_Trend': week_data['trend'],\n",
    "                            'Week_Change_Pct': week_data['price_change_pct']\n",
    "                        })\n",
    "                \n",
    "                # Create DataFrame and export\n",
    "                export_df = pd.DataFrame(export_data)\n",
    "                filename = f\"{commodity}_28day_predictions_{timestamp}.csv\"\n",
    "                export_df.to_csv(filename, index=False)\n",
    "                print(f\"‚úÖ Exported {commodity} predictions to {filename}\")\n",
    "        \n",
    "        # Export intervention analysis\n",
    "        if interventions:\n",
    "            intervention_df = pd.DataFrame(interventions)\n",
    "            intervention_filename = f\"market_interventions_{timestamp}.csv\"\n",
    "            intervention_df.to_csv(intervention_filename, index=False)\n",
    "            print(f\"‚úÖ Exported intervention analysis to {intervention_filename}\")\n",
    "        \n",
    "        print(f\"\\nüìÅ All reports exported with timestamp: {timestamp}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Export failed: {str(e)}\")\n",
    "\n",
    "def generate_summary_report():\n",
    "    \"\"\"Generate a comprehensive summary report\"\"\"\n",
    "    \n",
    "    try:\n",
    "        report = []\n",
    "        report.append(\"=\"*80)\n",
    "        report.append(\"üìä 28-DAY COMMODITY PRICE PREDICTION - EXECUTIVE SUMMARY\")\n",
    "        report.append(\"=\"*80)\n",
    "        \n",
    "        # Analysis details\n",
    "        from datetime import datetime as dt\n",
    "        report.append(f\"\\nüìÖ Analysis Date: {dt.now().strftime('%B %d, %Y')}\")\n",
    "        report.append(f\"üìà Prediction Period: 28 days (4 weeks)\")\n",
    "        report.append(f\"üè∑Ô∏è  Commodities Analyzed: {len(predictions)}\")\n",
    "        report.append(f\"üìä Data Source: {len(df)} total records\")\n",
    "        report.append(f\"üìç Districts Covered: {', '.join(df['District_Name'].unique()[:5])}\")\n",
    "        \n",
    "        # Key findings\n",
    "        report.append(f\"\\nüéØ KEY FINDINGS:\")\n",
    "        report.append(f\"‚Ä¢ {len(interventions)} commodities require market intervention\")\n",
    "        report.append(f\"‚Ä¢ {len(stable_commodities)} commodities show stable price trends\")\n",
    "        \n",
    "        if interventions:\n",
    "            highest_risk = max(interventions, key=lambda x: x['Risk_Score'])\n",
    "            report.append(f\"‚Ä¢ Highest risk commodity: {highest_risk['Commodity']} ({highest_risk['Risk_Score']:.1f} risk score)\")\n",
    "            \n",
    "            high_urgency = [item for item in interventions if 'HIGH' in item['Urgency_Level']]\n",
    "            report.append(f\"‚Ä¢ High urgency interventions needed: {len(high_urgency)}\")\n",
    "        \n",
    "        # Commodity-wise summary\n",
    "        report.append(f\"\\nüìã COMMODITY-WISE PREDICTIONS:\")\n",
    "        report.append(\"-\" * 60)\n",
    "        \n",
    "        for commodity, weekly_pred in predictions.items():\n",
    "            if isinstance(weekly_pred, dict):\n",
    "                week1_avg = weekly_pred['Week_1']['avg_price']\n",
    "                week4_avg = weekly_pred['Week_4']['avg_price']\n",
    "                total_change = ((week4_avg - week1_avg) / week1_avg) * 100\n",
    "                \n",
    "                report.append(f\"‚Ä¢ {commodity}:\")\n",
    "                report.append(f\"  - Week 1 avg: ‚Çπ{week1_avg:.2f}\")\n",
    "                report.append(f\"  - Week 4 avg: ‚Çπ{week4_avg:.2f}\")\n",
    "                report.append(f\"  - Overall trend: {total_change:+.1f}%\")\n",
    "        \n",
    "        # Recommendations\n",
    "        report.append(f\"\\nüéØ STRATEGIC RECOMMENDATIONS:\")\n",
    "        if interventions:\n",
    "            report.append(\"‚Ä¢ IMMEDIATE ACTIONS REQUIRED:\")\n",
    "            for item in interventions[:3]:  # Top 3\n",
    "                report.append(f\"  - {item['Commodity']}: {item['Recommendation']}\")\n",
    "        \n",
    "        report.append(\"‚Ä¢ MONITORING PRIORITIES:\")\n",
    "        report.append(\"  - Continue daily price tracking for all commodities\")\n",
    "        report.append(\"  - Weekly model retraining recommended\")\n",
    "        report.append(\"  - Consider expanding historical data for better accuracy\")\n",
    "        \n",
    "        # Save report\n",
    "        report_text = \"\\n\".join(report)\n",
    "        \n",
    "        timestamp = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        report_filename = f\"commodity_analysis_summary_{timestamp}.txt\"\n",
    "        \n",
    "        with open(report_filename, 'w') as f:\n",
    "            f.write(report_text)\n",
    "        \n",
    "        print(report_text)\n",
    "        print(f\"\\n‚úÖ Summary report saved to {report_filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Report generation failed: {str(e)}\")\n",
    "\n",
    "# Execute exports and reporting\n",
    "if 'predictions' in locals() and predictions:\n",
    "    print(\"\\nüìÅ Exporting results...\")\n",
    "    export_predictions_to_csv()\n",
    "    generate_summary_report()\n",
    "    \n",
    "    print(\"\\nüéâ COMPLETE 28-DAY COMMODITY PRICE PREDICTION SYSTEM EXECUTED SUCCESSFULLY!\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"‚úÖ All analysis completed\")\n",
    "    print(\"üìä Predictions generated for multiple commodities\")  \n",
    "    print(\"üö® Market intervention recommendations provided\")\n",
    "    print(\"üìÅ Results exported to CSV files\")\n",
    "    print(\"üìã Summary report generated\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No predictions available for export. Please run the analysis first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
