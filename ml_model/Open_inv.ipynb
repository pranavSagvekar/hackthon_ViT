{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aabd4d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (11991, 10)\n",
      "Columns: ['Column1', 'Column2', 'Column3', 'Column4', 'Column5', 'Column6', 'Column7', 'Column8', 'Column9', 'Column10']\n",
      "\n",
      "First few rows:\n",
      "  Column1                    Column2                    Column3    Column4  \\\n",
      "0  Sl no.              District Name                Market Name  Commodity   \n",
      "1       1  Chattrapati Sambhajinagar  Chattrapati Sambhajinagar      Apple   \n",
      "2       2  Chattrapati Sambhajinagar  Chattrapati Sambhajinagar      Apple   \n",
      "3       3  Chattrapati Sambhajinagar  Chattrapati Sambhajinagar      Apple   \n",
      "4       4  Chattrapati Sambhajinagar  Chattrapati Sambhajinagar      Apple   \n",
      "\n",
      "   Column5 Column6                  Column7                  Column8  \\\n",
      "0  Variety   Grade  Min Price (Rs./Quintal)  Max Price (Rs./Quintal)   \n",
      "1    Other   Local                     1000                    15000   \n",
      "2    Other   Local                     3400                     9700   \n",
      "3    Other   Local                     3500                     8500   \n",
      "4    Other   Local                     3500                     9500   \n",
      "\n",
      "                     Column9    Column10  \n",
      "0  Modal Price (Rs./Quintal)  Price Date  \n",
      "1                      12500   12-Jan-25  \n",
      "2                       6550   24-Oct-24  \n",
      "3                       6000   23-Sep-24  \n",
      "4                       6500    9-Dec-24  \n",
      "\n",
      "Data shape after cleaning: (11990, 10)\n",
      "Date range: 2024-07-27 00:00:00 to 2025-07-27 00:00:00\n",
      "Unique commodities: 10\n",
      "Unique districts: 5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the data - the CSV has proper headers\n",
    "df = pd.read_csv('fulldataOG(1).csv')\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "# Clean column names for easier handling\n",
    "df.columns = ['Sl_no', 'District_Name', 'Market_Name', 'Commodity', \n",
    "              'Variety', 'Grade', 'Min_Price', 'Max_Price', 'Modal_Price', 'Price_Date']\n",
    "\n",
    "# Convert data types\n",
    "numeric_columns = ['Min_Price', 'Max_Price', 'Modal_Price']\n",
    "for col in numeric_columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Convert Price_Date to datetime\n",
    "df['Price_Date'] = pd.to_datetime(df['Price_Date'], format='%d-%b-%y', errors='coerce')\n",
    "\n",
    "# Remove rows with invalid data\n",
    "df = df.dropna(subset=['Price_Date', 'Modal_Price']).reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nData shape after cleaning: {df.shape}\")\n",
    "print(f\"Date range: {df['Price_Date'].min()} to {df['Price_Date'].max()}\")\n",
    "print(f\"Unique commodities: {df['Commodity'].nunique()}\")\n",
    "print(f\"Unique districts: {df['District_Name'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1c44587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating lag features...\n",
      "Lag features created successfully!\n",
      "Final dataset shape: (11990, 25)\n",
      "Columns with lag features:\n",
      "['Modal_Price_lag_1', 'Modal_Price_lag_7', 'Modal_Price_lag_30', 'Modal_Price_MA_7', 'Modal_Price_MA_30']\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features_fixed(df):\n",
    "    \"\"\"\n",
    "    Create lag features with proper index handling to avoid reindex errors\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy to avoid modifying original dataframe\n",
    "    df_with_lags = df.copy()\n",
    "    \n",
    "    # Extract time features first\n",
    "    df_with_lags['Year'] = df_with_lags['Price_Date'].dt.year\n",
    "    df_with_lags['Month'] = df_with_lags['Price_Date'].dt.month\n",
    "    df_with_lags['Day'] = df_with_lags['Price_Date'].dt.day\n",
    "    df_with_lags['DayOfWeek'] = df_with_lags['Price_Date'].dt.dayofweek\n",
    "    df_with_lags['Quarter'] = df_with_lags['Price_Date'].dt.quarter\n",
    "    \n",
    "    # Create price-related features\n",
    "    df_with_lags['Price_Range'] = df_with_lags['Max_Price'] - df_with_lags['Min_Price']\n",
    "    df_with_lags['Price_Volatility'] = np.where(\n",
    "        df_with_lags['Modal_Price'] != 0, \n",
    "        df_with_lags['Price_Range'] / df_with_lags['Modal_Price'], \n",
    "        0\n",
    "    )\n",
    "    \n",
    "    # Create seasonal indicators\n",
    "    df_with_lags['Is_Summer'] = df_with_lags['Month'].isin([3, 4, 5]).astype(int)\n",
    "    df_with_lags['Is_Monsoon'] = df_with_lags['Month'].isin([6, 7, 8, 9]).astype(int)\n",
    "    df_with_lags['Is_Winter'] = df_with_lags['Month'].isin([10, 11, 12, 1, 2]).astype(int)\n",
    "    \n",
    "    # Create lag features using a more robust method\n",
    "    print(\"Creating lag features...\")\n",
    "    \n",
    "    # Group by commodity and district\n",
    "    grouped = df_with_lags.groupby(['Commodity', 'District_Name'])\n",
    "    \n",
    "    # Initialize lag columns with NaN\n",
    "    for lag in [1, 7, 30]:\n",
    "        df_with_lags[f'Modal_Price_lag_{lag}'] = np.nan\n",
    "    \n",
    "    for window in [7, 30]:\n",
    "        df_with_lags[f'Modal_Price_MA_{window}'] = np.nan\n",
    "    \n",
    "    # Create lag features group by group\n",
    "    lag_data = []\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        group_sorted = group.sort_values('Price_Date').copy()\n",
    "        \n",
    "        # Create lag features for this group\n",
    "        for lag in [1, 7, 30]:\n",
    "            group_sorted[f'Modal_Price_lag_{lag}'] = group_sorted['Modal_Price'].shift(lag)\n",
    "        \n",
    "        # Create moving averages for this group\n",
    "        for window in [7, 30]:\n",
    "            group_sorted[f'Modal_Price_MA_{window}'] = (\n",
    "                group_sorted['Modal_Price']\n",
    "                .rolling(window=window, min_periods=1)\n",
    "                .mean()\n",
    "            )\n",
    "        \n",
    "        lag_data.append(group_sorted)\n",
    "    \n",
    "    # Concatenate all groups back together\n",
    "    df_with_lags = pd.concat(lag_data, ignore_index=True)\n",
    "    \n",
    "    # Sort by original order\n",
    "    df_with_lags = df_with_lags.sort_values(['Commodity', 'District_Name', 'Price_Date']).reset_index(drop=True)\n",
    "    \n",
    "    print(\"Lag features created successfully!\")\n",
    "    return df_with_lags\n",
    "\n",
    "# Apply the corrected feature engineering\n",
    "df = create_lag_features_fixed(df)\n",
    "\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "print(\"Columns with lag features:\")\n",
    "lag_cols = [col for col in df.columns if 'lag' in col or 'MA' in col]\n",
    "print(lag_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d5375bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding categorical variables...\n",
      "Categorical encoding completed!\n",
      "\n",
      "Checking for missing values:\n",
      "Sl_no                    0\n",
      "District_Name            0\n",
      "Market_Name              0\n",
      "Commodity                0\n",
      "Variety                  0\n",
      "Grade                    0\n",
      "Min_Price                0\n",
      "Max_Price                0\n",
      "Modal_Price              0\n",
      "Price_Date               0\n",
      "Year                     0\n",
      "Month                    0\n",
      "Day                      0\n",
      "DayOfWeek                0\n",
      "Quarter                  0\n",
      "Price_Range              0\n",
      "Price_Volatility         0\n",
      "Is_Summer                0\n",
      "Is_Monsoon               0\n",
      "Is_Winter                0\n",
      "Modal_Price_lag_1       49\n",
      "Modal_Price_lag_7      337\n",
      "Modal_Price_lag_30    1433\n",
      "Modal_Price_MA_7         0\n",
      "Modal_Price_MA_30        0\n",
      "Commodity_encoded        0\n",
      "District_encoded         0\n",
      "Variety_encoded          0\n",
      "Grade_encoded            0\n",
      "dtype: int64\n",
      "\n",
      "Sample of processed data:\n",
      "  Commodity              District_Name  Modal_Price Price_Date  \\\n",
      "0     Apple  Chattrapati Sambhajinagar       9500.0 2024-09-01   \n",
      "1     Apple  Chattrapati Sambhajinagar       9750.0 2024-09-04   \n",
      "2     Apple  Chattrapati Sambhajinagar       8000.0 2024-09-07   \n",
      "3     Apple  Chattrapati Sambhajinagar       7500.0 2024-09-08   \n",
      "4     Apple  Chattrapati Sambhajinagar       8000.0 2024-09-09   \n",
      "5     Apple  Chattrapati Sambhajinagar       7000.0 2024-09-11   \n",
      "6     Apple  Chattrapati Sambhajinagar       8750.0 2024-09-12   \n",
      "7     Apple  Chattrapati Sambhajinagar       7400.0 2024-09-14   \n",
      "8     Apple  Chattrapati Sambhajinagar       8000.0 2024-09-17   \n",
      "9     Apple  Chattrapati Sambhajinagar       7100.0 2024-09-19   \n",
      "\n",
      "   Modal_Price_lag_1  Modal_Price_MA_7  \n",
      "0                NaN       9500.000000  \n",
      "1             9500.0       9625.000000  \n",
      "2             9750.0       9083.333333  \n",
      "3             8000.0       8687.500000  \n",
      "4             7500.0       8550.000000  \n",
      "5             8000.0       8291.666667  \n",
      "6             7000.0       8357.142857  \n",
      "7             8750.0       8057.142857  \n",
      "8             7400.0       7807.142857  \n",
      "9             8000.0       7678.571429  \n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "print(\"Encoding categorical variables...\")\n",
    "\n",
    "le_commodity = LabelEncoder()\n",
    "le_district = LabelEncoder()\n",
    "le_variety = LabelEncoder()\n",
    "le_grade = LabelEncoder()\n",
    "\n",
    "df['Commodity_encoded'] = le_commodity.fit_transform(df['Commodity'].astype(str))\n",
    "df['District_encoded'] = le_district.fit_transform(df['District_Name'].astype(str))\n",
    "df['Variety_encoded'] = le_variety.fit_transform(df['Variety'].astype(str))\n",
    "df['Grade_encoded'] = le_grade.fit_transform(df['Grade'].astype(str))\n",
    "\n",
    "print(\"Categorical encoding completed!\")\n",
    "\n",
    "# Check for any remaining NaN values\n",
    "print(\"\\nChecking for missing values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Display sample of processed data\n",
    "print(\"\\nSample of processed data:\")\n",
    "sample_cols = ['Commodity', 'District_Name', 'Modal_Price', 'Price_Date', \n",
    "               'Modal_Price_lag_1', 'Modal_Price_MA_7']\n",
    "print(df[sample_cols].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22af4077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (2.2.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (1.15.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Total features: 21\n",
      "Features: ['Commodity_encoded', 'District_encoded', 'Variety_encoded', 'Grade_encoded', 'Year', 'Month', 'Day', 'DayOfWeek', 'Quarter', 'Min_Price', 'Max_Price', 'Price_Range', 'Price_Volatility', 'Is_Summer', 'Is_Monsoon', 'Is_Winter', 'Modal_Price_lag_1', 'Modal_Price_lag_7', 'Modal_Price_lag_30', 'Modal_Price_MA_7', 'Modal_Price_MA_30']\n",
      "ML training data shape after removing NaN: (10557, 22)\n",
      "\n",
      "Training models...\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ“ Random Forest - MAE: 52.31, RÂ²: 0.995\n",
      "Training Gradient Boosting...\n",
      "  âœ“ Gradient Boosting - MAE: 66.79, RÂ²: 0.996\n",
      "Training Linear Regression...\n",
      "  âœ“ Linear Regression - MAE: 135.94, RÂ²: 0.924\n",
      "Training XGBoost...\n",
      "  âœ“ XGBoost - MAE: 56.49, RÂ²: 0.996\n",
      "\n",
      "ðŸ† Best model: Random Forest (MAE: 52.31)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "%pip install xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# Define feature columns\n",
    "feature_columns = [\n",
    "    'Commodity_encoded', 'District_encoded', 'Variety_encoded', 'Grade_encoded',\n",
    "    'Year', 'Month', 'Day', 'DayOfWeek', 'Quarter',\n",
    "    'Min_Price', 'Max_Price', 'Price_Range', 'Price_Volatility',\n",
    "    'Is_Summer', 'Is_Monsoon', 'Is_Winter'\n",
    "]\n",
    "\n",
    "# Add lag features\n",
    "lag_features = [col for col in df.columns if 'lag' in col or 'MA' in col]\n",
    "feature_columns.extend(lag_features)\n",
    "\n",
    "print(f\"Total features: {len(feature_columns)}\")\n",
    "print(\"Features:\", feature_columns)\n",
    "\n",
    "# Prepare data for ML\n",
    "ml_df = df[feature_columns + ['Modal_Price']].copy()\n",
    "\n",
    "# Remove rows with NaN values (due to lag features)\n",
    "ml_df = ml_df.dropna().reset_index(drop=True)\n",
    "\n",
    "print(f\"ML training data shape after removing NaN: {ml_df.shape}\")\n",
    "\n",
    "if len(ml_df) == 0:\n",
    "    print(\"âŒ No data available after removing NaN values!\")\n",
    "    print(\"This might be due to insufficient data for lag features.\")\n",
    "    \n",
    "    # Try with fewer lag features\n",
    "    basic_features = [\n",
    "        'Commodity_encoded', 'District_encoded', 'Variety_encoded', 'Grade_encoded',\n",
    "        'Year', 'Month', 'Day', 'DayOfWeek', 'Quarter',\n",
    "        'Min_Price', 'Max_Price', 'Price_Range', 'Price_Volatility',\n",
    "        'Is_Summer', 'Is_Monsoon', 'Is_Winter'\n",
    "    ]\n",
    "    \n",
    "    ml_df = df[basic_features + ['Modal_Price']].dropna().reset_index(drop=True)\n",
    "    feature_columns = basic_features\n",
    "    print(f\"Using basic features only. New shape: {ml_df.shape}\")\n",
    "\n",
    "if len(ml_df) > 0:\n",
    "    X = ml_df[feature_columns]\n",
    "    y = ml_df['Modal_Price']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestRegressor(n_estimators=50, random_state=42, max_depth=10),\n",
    "        'Gradient Boosting': GradientBoostingRegressor(n_estimators=50, random_state=42, max_depth=5),\n",
    "        'Linear Regression': LinearRegression()\n",
    "    }\n",
    "    \n",
    "    # Add XGBoost if available\n",
    "    try:\n",
    "        models['XGBoost'] = xgb.XGBRegressor(n_estimators=50, random_state=42, max_depth=5)\n",
    "    except:\n",
    "        print(\"XGBoost not available, skipping...\")\n",
    "    \n",
    "    model_results = {}\n",
    "    \n",
    "    print(\"\\nTraining models...\")\n",
    "    for name, model in models.items():\n",
    "        try:\n",
    "            print(f\"Training {name}...\")\n",
    "            \n",
    "            if name == 'Linear Regression':\n",
    "                model.fit(X_train_scaled, y_train)\n",
    "                y_pred = model.predict(X_test_scaled)\n",
    "            else:\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "            \n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "            \n",
    "            model_results[name] = {\n",
    "                'model': model,\n",
    "                'MAE': mae,\n",
    "                'MSE': mse,\n",
    "                'R2': r2,\n",
    "                'scaler': scaler if name == 'Linear Regression' else None\n",
    "            }\n",
    "            \n",
    "            print(f\"  âœ“ {name} - MAE: {mae:.2f}, RÂ²: {r2:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ {name} failed: {str(e)}\")\n",
    "    \n",
    "    # Find best model\n",
    "    if model_results:\n",
    "        best_model_name = min(model_results.keys(), key=lambda x: model_results[x]['MAE'])\n",
    "        print(f\"\\nðŸ† Best model: {best_model_name} (MAE: {model_results[best_model_name]['MAE']:.2f})\")\n",
    "    else:\n",
    "        print(\"âŒ No models trained successfully!\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ Cannot proceed with ML training - no valid data available!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8beb919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.14.4)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (2.2.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (1.15.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (2.2.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from statsmodels) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\atharva\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Building ARIMA models for time series forecasting...\n",
      "âœ“ ARIMA model built for Apple\n",
      "âœ“ ARIMA model built for Banana\n",
      "âœ“ ARIMA model built for Brinjal\n",
      "âœ“ ARIMA model built for Cabbage\n",
      "âœ“ ARIMA model built for Grapes\n",
      "âœ“ ARIMA model built for Guava\n",
      "âœ“ ARIMA model built for Onion\n",
      "âœ“ ARIMA model built for Papaya\n",
      "âœ“ ARIMA model built for Potato\n",
      "âœ“ ARIMA model built for Tomato\n",
      "ARIMA models built for 10 commodities\n"
     ]
    }
   ],
   "source": [
    "%pip install statsmodels\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def build_arima_models():\n",
    "    \"\"\"Build ARIMA models for each commodity\"\"\"\n",
    "    \n",
    "    print(\"Building ARIMA models for time series forecasting...\")\n",
    "    arima_models = {}\n",
    "    \n",
    "    commodities = df['Commodity'].unique()\n",
    "    \n",
    "    for commodity in commodities:\n",
    "        try:\n",
    "            # Get commodity data\n",
    "            commodity_data = df[df['Commodity'] == commodity].copy()\n",
    "            \n",
    "            if len(commodity_data) < 50:  # Need sufficient data\n",
    "                continue\n",
    "            \n",
    "            # Create time series\n",
    "            ts_data = (commodity_data.groupby('Price_Date')['Modal_Price']\n",
    "                      .mean()\n",
    "                      .resample('D')\n",
    "                      .mean()\n",
    "                      .fillna(method='ffill')\n",
    "                      .dropna())\n",
    "            \n",
    "            if len(ts_data) < 30:\n",
    "                continue\n",
    "            \n",
    "            # Simple ARIMA model (you can optimize parameters later)\n",
    "            model = ARIMA(ts_data, order=(1, 1, 1))\n",
    "            fitted_model = model.fit()\n",
    "            \n",
    "            arima_models[commodity] = {\n",
    "                'model': fitted_model,\n",
    "                'data': ts_data,\n",
    "                'last_date': ts_data.index[-1],\n",
    "                'last_price': ts_data.iloc[-1]\n",
    "            }\n",
    "            \n",
    "            print(f\"âœ“ ARIMA model built for {commodity}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ARIMA failed for {commodity}: {str(e)}\")\n",
    "    \n",
    "    print(f\"ARIMA models built for {len(arima_models)} commodities\")\n",
    "    return arima_models\n",
    "\n",
    "# Build ARIMA models\n",
    "arima_models = build_arima_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "042955f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing price prediction...\n",
      "Predicting prices for Apple\n",
      "        Date  Predicted_Price Method Commodity       District\n",
      "0 2025-07-28     11183.091018  ARIMA     Apple  All Districts\n",
      "1 2025-07-29     11183.069101  ARIMA     Apple  All Districts\n",
      "2 2025-07-30     11183.069130  ARIMA     Apple  All Districts\n",
      "3 2025-07-31     11183.069130  ARIMA     Apple  All Districts\n",
      "4 2025-08-01     11183.069130  ARIMA     Apple  All Districts\n",
      "5 2025-08-02     11183.069130  ARIMA     Apple  All Districts\n",
      "6 2025-08-03     11183.069130  ARIMA     Apple  All Districts\n",
      "7 2025-08-04     11183.069130  ARIMA     Apple  All Districts\n",
      "8 2025-08-05     11183.069130  ARIMA     Apple  All Districts\n",
      "9 2025-08-06     11183.069130  ARIMA     Apple  All Districts\n"
     ]
    }
   ],
   "source": [
    "def predict_future_prices(commodity, district=None, days_ahead=30):\n",
    "    \"\"\"\n",
    "    Predict future prices for a specific commodity (and optionally district)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Predicting prices for {commodity}\" + (f\" in {district}\" if district else \"\"))\n",
    "    \n",
    "    # Filter data\n",
    "    if district:\n",
    "        filtered_data = df[(df['Commodity'] == commodity) & \n",
    "                          (df['District_Name'] == district)].copy()\n",
    "    else:\n",
    "        filtered_data = df[df['Commodity'] == commodity].copy()\n",
    "    \n",
    "    if len(filtered_data) == 0:\n",
    "        return f\"No data available for {commodity}\" + (f\" in {district}\" if district else \"\")\n",
    "    \n",
    "    # Try ARIMA first (better for time series)\n",
    "    if commodity in arima_models:\n",
    "        try:\n",
    "            arima_model = arima_models[commodity]['model']\n",
    "            forecast = arima_model.forecast(steps=days_ahead)\n",
    "            \n",
    "            # Create forecast dates\n",
    "            last_date = arima_models[commodity]['last_date']\n",
    "            forecast_dates = pd.date_range(\n",
    "                start=last_date + pd.Timedelta(days=1),\n",
    "                periods=days_ahead,\n",
    "                freq='D'\n",
    "            )\n",
    "            \n",
    "            return pd.DataFrame({\n",
    "                'Date': forecast_dates,\n",
    "                'Predicted_Price': forecast.values,\n",
    "                'Method': 'ARIMA',\n",
    "                'Commodity': commodity,\n",
    "                'District': district if district else 'All Districts'\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ARIMA prediction failed: {e}, falling back to ML model\")\n",
    "    \n",
    "    # Fallback to ML model\n",
    "    try:\n",
    "        # Get latest data point\n",
    "        latest_data = filtered_data.sort_values('Price_Date').tail(1).copy()\n",
    "        \n",
    "        if len(latest_data) == 0:\n",
    "            return \"No recent data available\"\n",
    "        \n",
    "        # Check if we have all required features\n",
    "        missing_features = [col for col in feature_columns if col not in latest_data.columns]\n",
    "        if missing_features:\n",
    "            print(f\"Missing features for ML prediction: {missing_features}\")\n",
    "            return \"Cannot make ML prediction - missing features\"\n",
    "        \n",
    "        # Prepare for prediction\n",
    "        predictions = []\n",
    "        current_data = latest_data.copy()\n",
    "        \n",
    "        best_model = model_results[best_model_name]['model']\n",
    "        best_scaler = model_results[best_model_name]['scaler']\n",
    "        \n",
    "        for i in range(days_ahead):\n",
    "            # Get features\n",
    "            try:\n",
    "                X_pred = current_data[feature_columns].values\n",
    "                \n",
    "                # Handle any remaining NaN values\n",
    "                if np.isnan(X_pred).any():\n",
    "                    # Fill with median values from training data\n",
    "                    X_pred = np.where(np.isnan(X_pred), \n",
    "                                    np.nanmedian(X_train.values, axis=0), \n",
    "                                    X_pred)\n",
    "                \n",
    "                # Scale if needed\n",
    "                if best_model_name == 'Linear Regression' and best_scaler:\n",
    "                    X_pred = best_scaler.transform(X_pred)\n",
    "                \n",
    "                # Make prediction\n",
    "                prediction = best_model.predict(X_pred)[0]\n",
    "                \n",
    "                # Ensure positive price\n",
    "                prediction = max(prediction, 0)\n",
    "                predictions.append(prediction)\n",
    "                \n",
    "                # Update for next iteration (simple approach)\n",
    "                current_data['Modal_Price'] = prediction\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in prediction step {i}: {e}\")\n",
    "                break\n",
    "        \n",
    "        # Create forecast dates\n",
    "        last_date = latest_data['Price_Date'].iloc[0]\n",
    "        forecast_dates = pd.date_range(\n",
    "            start=last_date + pd.Timedelta(days=1),\n",
    "            periods=len(predictions),\n",
    "            freq='D'\n",
    "        )\n",
    "        \n",
    "        return pd.DataFrame({\n",
    "            'Date': forecast_dates,\n",
    "            'Predicted_Price': predictions,\n",
    "            'Method': f'ML ({best_model_name})',\n",
    "            'Commodity': commodity,\n",
    "            'District': district if district else 'All Districts'\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Prediction failed: {str(e)}\"\n",
    "\n",
    "# Test the prediction function\n",
    "print(\"Testing price prediction...\")\n",
    "test_commodity = df['Commodity'].iloc[0]\n",
    "test_prediction = predict_future_prices(test_commodity, days_ahead=10)\n",
    "print(test_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62b7855e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMPREHENSIVE MARKET INTERVENTION ANALYSIS\n",
      "============================================================\n",
      "\n",
      "=== Market Intervention Analysis for Apple ===\n",
      "Predicting prices for Apple\n",
      "\n",
      "=== Market Intervention Analysis for Banana ===\n",
      "Predicting prices for Banana\n",
      "\n",
      "=== Market Intervention Analysis for Brinjal ===\n",
      "Predicting prices for Brinjal\n",
      "\n",
      "=== Market Intervention Analysis for Cabbage ===\n",
      "Predicting prices for Cabbage\n",
      "\n",
      "=== Market Intervention Analysis for Grapes ===\n",
      "Predicting prices for Grapes\n",
      "\n",
      "=== Market Intervention Analysis for Guava ===\n",
      "Predicting prices for Guava\n",
      "\n",
      "=== Market Intervention Analysis for Onion ===\n",
      "Predicting prices for Onion\n",
      "\n",
      "=== Market Intervention Analysis for Papaya ===\n",
      "Predicting prices for Papaya\n",
      "\n",
      "=== Market Intervention Analysis for Potato ===\n",
      "Predicting prices for Potato\n",
      "\n",
      "=== Market Intervention Analysis for Tomato ===\n",
      "Predicting prices for Tomato\n"
     ]
    }
   ],
   "source": [
    "def market_intervention_analysis(commodity, price_increase_threshold=20):\n",
    "    \"\"\"\n",
    "    Analyze if market intervention is needed for a specific commodity\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n=== Market Intervention Analysis for {commodity} ===\")\n",
    "    \n",
    "    # Get current average price\n",
    "    recent_data = df[df['Commodity'] == commodity].tail(30)\n",
    "    if len(recent_data) == 0:\n",
    "        return f\"No data available for {commodity}\"\n",
    "    \n",
    "    current_avg_price = recent_data['Modal_Price'].mean()\n",
    "    \n",
    "    # Get predictions for next 30 days\n",
    "    future_prices = predict_future_prices(commodity, days_ahead=30)\n",
    "    \n",
    "    if isinstance(future_prices, str):\n",
    "        return f\"Cannot analyze {commodity}: {future_prices}\"\n",
    "    \n",
    "    # Calculate price trends\n",
    "    max_predicted_price = future_prices['Predicted_Price'].max()\n",
    "    avg_predicted_price = future_prices['Predicted_Price'].mean()\n",
    "    \n",
    "    # Calculate percentage increase\n",
    "    max_increase_pct = ((max_predicted_price - current_avg_price) / current_avg_price) * 100\n",
    "    avg_increase_pct = ((avg_predicted_price - current_avg_price) / current_avg_price) * 100\n",
    "    \n",
    "    # Determine intervention need\n",
    "    intervention_needed = max_increase_pct > price_increase_threshold\n",
    "    \n",
    "    # Determine urgency\n",
    "    if max_increase_pct > 30:\n",
    "        urgency = \"HIGH\"\n",
    "    elif max_increase_pct > 20:\n",
    "        urgency = \"MEDIUM\"\n",
    "    else:\n",
    "        urgency = \"LOW\"\n",
    "    \n",
    "    analysis_result = {\n",
    "        'Commodity': commodity,\n",
    "        'Current_Avg_Price': round(current_avg_price, 2),\n",
    "        'Max_Predicted_Price': round(max_predicted_price, 2),\n",
    "        'Avg_Predicted_Price': round(avg_predicted_price, 2),\n",
    "        'Max_Price_Increase_Pct': round(max_increase_pct, 2),\n",
    "        'Avg_Price_Increase_Pct': round(avg_increase_pct, 2),\n",
    "        'Intervention_Needed': intervention_needed,\n",
    "        'Urgency_Level': urgency,\n",
    "        'Recommendation': 'RELEASE BUFFER STOCK' if intervention_needed else 'MONITOR PRICES',\n",
    "        'Districts_Affected': df[df['Commodity'] == commodity]['District_Name'].nunique()\n",
    "    }\n",
    "    \n",
    "    return analysis_result\n",
    "\n",
    "def analyze_all_commodities():\n",
    "    \"\"\"Analyze all commodities for market intervention needs\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"COMPREHENSIVE MARKET INTERVENTION ANALYSIS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    commodities = df['Commodity'].unique()\n",
    "    interventions_needed = []\n",
    "    stable_commodities = []\n",
    "    \n",
    "    for commodity in commodities:\n",
    "        try:\n",
    "            analysis = market_intervention_analysis(commodity)\n",
    "            \n",
    "            if isinstance(analysis, dict):\n",
    "                if analysis['Intervention_Needed']:\n",
    "                    interventions_needed.append(analysis)\n",
    "                else:\n",
    "                    stable_commodities.append(analysis)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Analysis failed for {commodity}: {e}\")\n",
    "    \n",
    "    # Sort by urgency and price increase\n",
    "    interventions_needed.sort(key=lambda x: (\n",
    "        0 if x['Urgency_Level'] == 'HIGH' else 1 if x['Urgency_Level'] == 'MEDIUM' else 2,\n",
    "        -x['Max_Price_Increase_Pct']\n",
    "    ))\n",
    "    \n",
    "    return interventions_needed, stable_commodities\n",
    "\n",
    "# Run comprehensive analysis\n",
    "interventions_needed, stable_commodities = analyze_all_commodities()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e208968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ðŸš¨ DEPARTMENT OF CONSUMER AFFAIRS - MARKET INTERVENTION REPORT\n",
      "================================================================================\n",
      "Report Generated: 2025-07-29 21:41:30\n",
      "\n",
      "ðŸ”´ IMMEDIATE INTERVENTIONS REQUIRED: 3 commodities\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "ðŸš¨ HIGH PRIORITY (>30% price increase expected):\n",
      "  â€¢ Tomato\n",
      "    Current Price: â‚¹1411.67\n",
      "    Expected Max Price: â‚¹2469.63\n",
      "    Price Increase: 74.9%\n",
      "    Districts Affected: 5\n",
      "    Action: RELEASE BUFFER STOCK\n",
      "\n",
      "ðŸŸ¡ MEDIUM PRIORITY (20-30% price increase expected):\n",
      "  â€¢ Guava: 23.6% increase expected\n",
      "  â€¢ Apple: 22.4% increase expected\n",
      "\n",
      "ðŸ“Š MARKET SUMMARY:\n",
      "  â€¢ Total commodities monitored: 10\n",
      "  â€¢ Commodities requiring intervention: 3\n",
      "  â€¢ Stable commodities: 7\n",
      "  â€¢ Districts covered: 5\n",
      "\n",
      "ðŸ“‹ DETAILED INTERVENTION TABLE:\n",
      "Commodity  Current_Avg_Price  Max_Predicted_Price  Max_Price_Increase_Pct Urgency_Level       Recommendation\n",
      "   Tomato            1411.67              2469.63                   74.94          HIGH RELEASE BUFFER STOCK\n",
      "    Guava            3230.00              3991.29                   23.57        MEDIUM RELEASE BUFFER STOCK\n",
      "    Apple            9133.33             11183.09                   22.44        MEDIUM RELEASE BUFFER STOCK\n"
     ]
    }
   ],
   "source": [
    "def generate_intervention_report():\n",
    "    \"\"\"Generate comprehensive intervention report\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸš¨ DEPARTMENT OF CONSUMER AFFAIRS - MARKET INTERVENTION REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Report Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    if interventions_needed:\n",
    "        print(f\"\\nðŸ”´ IMMEDIATE INTERVENTIONS REQUIRED: {len(interventions_needed)} commodities\")\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        # High priority interventions\n",
    "        high_priority = [x for x in interventions_needed if x['Urgency_Level'] == 'HIGH']\n",
    "        if high_priority:\n",
    "            print(\"\\nðŸš¨ HIGH PRIORITY (>30% price increase expected):\")\n",
    "            for item in high_priority:\n",
    "                print(f\"  â€¢ {item['Commodity']}\")\n",
    "                print(f\"    Current Price: â‚¹{item['Current_Avg_Price']}\")\n",
    "                print(f\"    Expected Max Price: â‚¹{item['Max_Predicted_Price']}\")\n",
    "                print(f\"    Price Increase: {item['Max_Price_Increase_Pct']:.1f}%\")\n",
    "                print(f\"    Districts Affected: {item['Districts_Affected']}\")\n",
    "                print(f\"    Action: {item['Recommendation']}\")\n",
    "                print()\n",
    "        \n",
    "        # Medium priority interventions\n",
    "        medium_priority = [x for x in interventions_needed if x['Urgency_Level'] == 'MEDIUM']\n",
    "        if medium_priority:\n",
    "            print(\"ðŸŸ¡ MEDIUM PRIORITY (20-30% price increase expected):\")\n",
    "            for item in medium_priority:\n",
    "                print(f\"  â€¢ {item['Commodity']}: {item['Max_Price_Increase_Pct']:.1f}% increase expected\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nâœ… NO IMMEDIATE INTERVENTIONS REQUIRED\")\n",
    "        print(\"All commodity prices are within acceptable ranges.\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š MARKET SUMMARY:\")\n",
    "    print(f\"  â€¢ Total commodities monitored: {len(df['Commodity'].unique())}\")\n",
    "    print(f\"  â€¢ Commodities requiring intervention: {len(interventions_needed)}\")\n",
    "    print(f\"  â€¢ Stable commodities: {len(stable_commodities)}\")\n",
    "    print(f\"  â€¢ Districts covered: {df['District_Name'].nunique()}\")\n",
    "    \n",
    "    # Create detailed intervention table\n",
    "    if interventions_needed:\n",
    "        print(f\"\\nðŸ“‹ DETAILED INTERVENTION TABLE:\")\n",
    "        intervention_df = pd.DataFrame(interventions_needed)\n",
    "        print(intervention_df[['Commodity', 'Current_Avg_Price', 'Max_Predicted_Price', \n",
    "                             'Max_Price_Increase_Pct', 'Urgency_Level', 'Recommendation']].to_string(index=False))\n",
    "    \n",
    "    return interventions_needed\n",
    "\n",
    "# Generate the final report\n",
    "final_report = generate_intervention_report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07d44a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ðŸ”® INTERACTIVE PRICE PREDICTION SYSTEM\n",
      "==================================================\n",
      "Available commodities: 10\n",
      "Available districts: 5\n",
      "\n",
      "Generating predictions for major commodities...\n",
      "\n",
      "--- APPLE PRICE FORECAST ---\n",
      "Predicting prices for Apple\n",
      "Next 7 days:\n",
      "      Date  Predicted_Price Method\n",
      "2025-07-28         11183.09  ARIMA\n",
      "2025-07-29         11183.07  ARIMA\n",
      "2025-07-30         11183.07  ARIMA\n",
      "2025-07-31         11183.07  ARIMA\n",
      "2025-08-01         11183.07  ARIMA\n",
      "2025-08-02         11183.07  ARIMA\n",
      "2025-08-03         11183.07  ARIMA\n",
      "Current avg: â‚¹8800.00\n",
      "7-day avg predicted: â‚¹11183.07\n",
      "Trend: ðŸ“ˆ INCREASING (+27.1%)\n",
      "\n",
      "--- BANANA PRICE FORECAST ---\n",
      "Predicting prices for Banana\n",
      "Next 7 days:\n",
      "      Date  Predicted_Price Method\n",
      "2025-07-28          1286.92  ARIMA\n",
      "2025-07-29          1293.49  ARIMA\n",
      "2025-07-30          1293.29  ARIMA\n",
      "2025-07-31          1293.30  ARIMA\n",
      "2025-08-01          1293.30  ARIMA\n",
      "2025-08-02          1293.30  ARIMA\n",
      "2025-08-03          1293.30  ARIMA\n",
      "Current avg: â‚¹1480.00\n",
      "7-day avg predicted: â‚¹1292.41\n",
      "Trend: ðŸ“‰ DECREASING (-12.7%)\n",
      "\n",
      "--- BRINJAL PRICE FORECAST ---\n",
      "Predicting prices for Brinjal\n",
      "Next 7 days:\n",
      "      Date  Predicted_Price Method\n",
      "2025-07-28          1892.84  ARIMA\n",
      "2025-07-29          1866.85  ARIMA\n",
      "2025-07-30          1870.35  ARIMA\n",
      "2025-07-31          1869.88  ARIMA\n",
      "2025-08-01          1869.94  ARIMA\n",
      "2025-08-02          1869.93  ARIMA\n",
      "2025-08-03          1869.94  ARIMA\n",
      "Current avg: â‚¹2150.00\n",
      "7-day avg predicted: â‚¹1872.82\n",
      "Trend: ðŸ“‰ DECREASING (-12.9%)\n",
      "\n",
      "--- CABBAGE PRICE FORECAST ---\n",
      "Predicting prices for Cabbage\n",
      "Next 7 days:\n",
      "      Date  Predicted_Price Method\n",
      "2025-07-28          1103.27  ARIMA\n",
      "2025-07-29          1103.28  ARIMA\n",
      "2025-07-30          1103.28  ARIMA\n",
      "2025-07-31          1103.28  ARIMA\n",
      "2025-08-01          1103.28  ARIMA\n",
      "2025-08-02          1103.28  ARIMA\n",
      "2025-08-03          1103.28  ARIMA\n",
      "Current avg: â‚¹1040.00\n",
      "7-day avg predicted: â‚¹1103.28\n",
      "Trend: ðŸ“ˆ INCREASING (+6.1%)\n",
      "\n",
      "--- GRAPES PRICE FORECAST ---\n",
      "Predicting prices for Grapes\n",
      "Next 7 days:\n",
      "      Date  Predicted_Price Method\n",
      "2025-07-28          9530.05  ARIMA\n",
      "2025-07-29          9048.13  ARIMA\n",
      "2025-07-30          8974.86  ARIMA\n",
      "2025-07-31          8963.73  ARIMA\n",
      "2025-08-01          8962.03  ARIMA\n",
      "2025-08-02          8961.78  ARIMA\n",
      "2025-08-03          8961.74  ARIMA\n",
      "Current avg: â‚¹11040.00\n",
      "7-day avg predicted: â‚¹9057.47\n",
      "Trend: ðŸ“‰ DECREASING (-18.0%)\n"
     ]
    }
   ],
   "source": [
    "def interactive_prediction_system():\n",
    "    \"\"\"Interactive system for specific commodity predictions\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ðŸ”® INTERACTIVE PRICE PREDICTION SYSTEM\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    available_commodities = df['Commodity'].unique()\n",
    "    available_districts = df['District_Name'].unique()\n",
    "    \n",
    "    print(f\"Available commodities: {len(available_commodities)}\")\n",
    "    print(f\"Available districts: {len(available_districts)}\")\n",
    "    \n",
    "    # Example predictions for major commodities\n",
    "    major_commodities = ['Apple', 'Banana', 'Brinjal', 'Cabbage', 'Grapes']\n",
    "    available_major = [c for c in major_commodities if c in available_commodities]\n",
    "    \n",
    "    if not available_major:\n",
    "        available_major = list(available_commodities)[:5]\n",
    "    \n",
    "    print(f\"\\nGenerating predictions for major commodities...\")\n",
    "    \n",
    "    for commodity in available_major:\n",
    "        print(f\"\\n--- {commodity.upper()} PRICE FORECAST ---\")\n",
    "        \n",
    "        # Get 15-day prediction\n",
    "        prediction = predict_future_prices(commodity, days_ahead=15)\n",
    "        \n",
    "        if isinstance(prediction, pd.DataFrame):\n",
    "            print(\"Next 7 days:\")\n",
    "            display_pred = prediction.head(7)[['Date', 'Predicted_Price', 'Method']]\n",
    "            display_pred['Date'] = display_pred['Date'].dt.strftime('%Y-%m-%d')\n",
    "            display_pred['Predicted_Price'] = display_pred['Predicted_Price'].round(2)\n",
    "            print(display_pred.to_string(index=False))\n",
    "            \n",
    "            # Show trend\n",
    "            current_price = df[df['Commodity'] == commodity]['Modal_Price'].tail(5).mean()\n",
    "            avg_predicted = prediction['Predicted_Price'].head(7).mean()\n",
    "            trend = \"ðŸ“ˆ INCREASING\" if avg_predicted > current_price else \"ðŸ“‰ DECREASING\"\n",
    "            change = ((avg_predicted - current_price) / current_price) * 100\n",
    "            \n",
    "            print(f\"Current avg: â‚¹{current_price:.2f}\")\n",
    "            print(f\"7-day avg predicted: â‚¹{avg_predicted:.2f}\")\n",
    "            print(f\"Trend: {trend} ({change:+.1f}%)\")\n",
    "        else:\n",
    "            print(prediction)\n",
    "\n",
    "# Run the interactive system\n",
    "interactive_prediction_system()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff71aef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Models and results saved successfully!\n",
      "Files created:\n",
      "  â€¢ price_prediction_models.pkl\n",
      "  â€¢ arima_models.pkl\n",
      "  â€¢ intervention_recommendations.csv\n",
      "  â€¢ feature_columns.pkl\n"
     ]
    }
   ],
   "source": [
    "def save_models_and_results():\n",
    "    \"\"\"Save trained models and results for future use\"\"\"\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    # Save ML models\n",
    "    with open('price_prediction_models.pkl', 'wb') as f:\n",
    "        pickle.dump(model_results, f)\n",
    "    \n",
    "    # Save ARIMA models\n",
    "    with open('arima_models.pkl', 'wb') as f:\n",
    "        pickle.dump(arima_models, f)\n",
    "    \n",
    "    # Save intervention results\n",
    "    if interventions_needed:\n",
    "        intervention_df = pd.DataFrame(interventions_needed)\n",
    "        intervention_df.to_csv('intervention_recommendations.csv', index=False)\n",
    "    \n",
    "    # Save feature columns for future predictions\n",
    "    with open('feature_columns.pkl', 'wb') as f:\n",
    "        pickle.dump(feature_columns, f)\n",
    "    \n",
    "    print(\"âœ… Models and results saved successfully!\")\n",
    "    print(\"Files created:\")\n",
    "    print(\"  â€¢ price_prediction_models.pkl\")\n",
    "    print(\"  â€¢ arima_models.pkl\") \n",
    "    print(\"  â€¢ intervention_recommendations.csv\")\n",
    "    print(\"  â€¢ feature_columns.pkl\")\n",
    "\n",
    "# Save everything\n",
    "save_models_and_results()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
